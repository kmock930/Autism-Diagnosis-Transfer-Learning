{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.410107Z",
     "start_time": "2024-11-09T01:37:17.172451Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, losses, optimizers, metrics\n",
    "\n",
    "from model_train import load_c3d_model, train_msupcl_model, linear_evaluation\n",
    "from data_uniform_sup import VideoDataGenerator\n",
    "from paired_generator import PairedDataGenerator"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.425626Z",
     "start_time": "2024-11-09T01:37:20.414114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 2042\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "input_shape = (16, 112, 112, 3)  # As defined in data generator\n",
    "num_classes = 2  # Harmful or Safe"
   ],
   "id": "dd29972a569d4e84",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.504296Z",
     "start_time": "2024-11-09T01:37:20.489264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define dataset paths\n",
    "violence_negative_dir = './data/violence_dataset/NonViolence'\n",
    "violence_positive_dir = './data/violence_dataset/Violence'\n",
    "tiktok_negative_dir = './data/tiktok/train/Safe'\n",
    "tiktok_positive_dir = './data/tiktok/train/Harmful Content'\n"
   ],
   "id": "38b4e7f27f35b855",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.535912Z",
     "start_time": "2024-11-09T01:37:20.521393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_videos(directory, num_samples=100):\n",
    "    all_videos = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.mp4')]\n",
    "    sampled_videos = random.sample(all_videos, min(num_samples, len(all_videos)))\n",
    "    return sampled_videos\n"
   ],
   "id": "69be9a7b8c19f6d5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.566978Z",
     "start_time": "2024-11-09T01:37:20.552461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Violence dataset\n",
    "violence_negative_videos = sample_videos(violence_negative_dir, 100)\n",
    "violence_positive_videos = sample_videos(violence_positive_dir, 100)\n",
    "\n",
    "# TikTok dataset\n",
    "tiktok_negative_videos = sample_videos(tiktok_negative_dir, 100)\n",
    "tiktok_positive_videos = sample_videos(tiktok_positive_dir, 100)\n"
   ],
   "id": "43cccf67e2dcc321",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.598542Z",
     "start_time": "2024-11-09T01:37:20.585014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_data(negative_videos, positive_videos, train_ratio=0.55, val_ratio=0.15):\n",
    "    # Combine and shuffle\n",
    "    videos = negative_videos + positive_videos\n",
    "    labels = [0]*len(negative_videos) + [1]*len(positive_videos)\n",
    "    combined = list(zip(videos, labels))\n",
    "    random.shuffle(combined)\n",
    "    videos[:], labels[:] = zip(*combined)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    total = len(videos)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = train_end + int(total * val_ratio)\n",
    "    \n",
    "    # Split data\n",
    "    train_videos = videos[:train_end]\n",
    "    train_labels = labels[:train_end]\n",
    "    val_videos = videos[train_end:val_end]\n",
    "    val_labels = labels[train_end:val_end]\n",
    "    test_videos = videos[val_end:]\n",
    "    test_labels = labels[val_end:]\n",
    "    \n",
    "    return (train_videos, train_labels), (val_videos, val_labels), (test_videos, test_labels)\n"
   ],
   "id": "f8fa8efe1d13ebf5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.630109Z",
     "start_time": "2024-11-09T01:37:20.615580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Violence dataset\n",
    "(violence_train_videos, violence_train_labels), \\\n",
    "(violence_val_videos, violence_val_labels), \\\n",
    "(violence_test_videos, violence_test_labels) = split_data(violence_negative_videos, violence_positive_videos)\n",
    "\n",
    "# TikTok dataset\n",
    "(tiktok_train_videos, tiktok_train_labels), \\\n",
    "(tiktok_val_videos, tiktok_val_labels), \\\n",
    "(tiktok_test_videos, tiktok_test_labels) = split_data(tiktok_negative_videos, tiktok_positive_videos)\n"
   ],
   "id": "17bc85a97ca94a61",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.677331Z",
     "start_time": "2024-11-09T01:37:20.662802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Convert labels to numpy arrays and one-hot encode them if necessary\n",
    "def prepare_labels(labels):\n",
    "    return np.array(labels)\n",
    "\n",
    "# Violence dataset generators\n",
    "violence_train_labels_np = prepare_labels(violence_train_labels)\n",
    "violence_val_labels_np = prepare_labels(violence_val_labels)\n",
    "violence_test_labels_np = prepare_labels(violence_test_labels)\n",
    "\n",
    "violence_train_generator = VideoDataGenerator(violence_train_videos, violence_train_labels_np, batch_size=4, shuffle=True, augment=True)\n",
    "violence_val_generator = VideoDataGenerator(violence_val_videos, violence_val_labels_np, batch_size=4, shuffle=False)\n",
    "violence_test_generator = VideoDataGenerator(violence_test_videos, violence_test_labels_np, batch_size=4, shuffle=False)"
   ],
   "id": "f150cbe36dce5ba1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:20.693367Z",
     "start_time": "2024-11-09T01:37:20.681840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# TikTok dataset generators\n",
    "tiktok_train_labels_np = prepare_labels(tiktok_train_labels)\n",
    "tiktok_val_labels_np = prepare_labels(tiktok_val_labels)\n",
    "tiktok_test_labels_np = prepare_labels(tiktok_test_labels)\n",
    "\n",
    "tiktok_train_generator = VideoDataGenerator(tiktok_train_videos, tiktok_train_labels_np, batch_size=4, shuffle=True, augment=True)\n",
    "tiktok_val_generator = VideoDataGenerator(tiktok_val_videos, tiktok_val_labels_np, batch_size=4, shuffle=False)\n",
    "tiktok_test_generator = VideoDataGenerator(tiktok_test_videos, tiktok_test_labels_np, batch_size=4, shuffle=False)\n"
   ],
   "id": "b129d04af287a968",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:52:04.797150Z",
     "start_time": "2024-11-09T00:52:03.827365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the model\n",
    "model = load_c3d_model(input_shape=input_shape, feature_dim=512)\n"
   ],
   "id": "b4c77a016021fe8f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:52:04.844298Z",
     "start_time": "2024-11-09T00:52:04.814182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modify the model to output class probabilities\n",
    "\n",
    "\n",
    "# Freeze the base model if desired\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add classification layer\n",
    "features = model.output\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(features)\n",
    "classification_model = models.Model(inputs=model.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "classification_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")\n"
   ],
   "id": "600a86c162f46bac",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:55:28.898711Z",
     "start_time": "2024-11-09T00:52:04.861876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train on Violence dataset\n",
    "history_violence = classification_model.fit(\n",
    "    violence_train_generator,\n",
    "    validation_data=violence_val_generator,\n",
    "    epochs=10\n",
    ")\n"
   ],
   "id": "80ad2bb7d4358a76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 24s 728ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.4630 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 20s 734ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.4815 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 20s 724ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.5046 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 20s 744ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.4491 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 20s 744ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.4954 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 20s 738ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.4815 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 20s 749ms/step - loss: 0.6937 - sparse_categorical_accuracy: 0.4861 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 20s 721ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.4676 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 20s 719ms/step - loss: 0.6929 - sparse_categorical_accuracy: 0.5278 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 20s 713ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.4676 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.4643\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:55:37.925898Z",
     "start_time": "2024-11-09T00:55:28.916796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate on Violence test set\n",
    "results_violence = classification_model.evaluate(violence_test_generator)\n",
    "print(f\"Violence Dataset - Test Loss: {results_violence[0]}, Test Accuracy: {results_violence[1]}\")\n"
   ],
   "id": "63b234494c99c2b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 9s 584ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.5167\n",
      "Violence Dataset - Test Loss: 0.6931942701339722, Test Accuracy: 0.5166666507720947\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:06:09.395019Z",
     "start_time": "2024-11-09T00:55:37.943011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_tiktok = classification_model.fit(\n",
    "    tiktok_train_generator,\n",
    "    validation_data=tiktok_val_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate on TikTok test set\n",
    "results_tiktok = classification_model.evaluate(tiktok_test_generator)\n",
    "print(f\"TikTok Dataset - Test Loss: {results_tiktok[0]}, Test Accuracy: {results_tiktok[1]}\")"
   ],
   "id": "7b2014bcbf1669c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 61s 2s/step - loss: 0.6945 - sparse_categorical_accuracy: 0.4120 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.6071\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 59s 2s/step - loss: 0.6930 - sparse_categorical_accuracy: 0.4769 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6934 - sparse_categorical_accuracy: 0.4769 - val_loss: 0.6934 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6925 - sparse_categorical_accuracy: 0.5046 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 61s 2s/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5556 - val_loss: 0.6938 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5602 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5509 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5602 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5509 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 60s 2s/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5463 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.3929\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.6941 - sparse_categorical_accuracy: 0.4500\n",
      "TikTok Dataset - Test Loss: 0.6941482424736023, Test Accuracy: 0.44999998807907104\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MSupCL implementation",
   "id": "dcd22c96fe0ecab0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:51:30.205580Z",
     "start_time": "2024-11-09T01:51:30.188445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine training data from both datasets\n",
    "combined_train_videos = violence_train_videos + tiktok_train_videos\n",
    "combined_train_labels = violence_train_labels_np.tolist() + tiktok_train_labels_np.tolist()\n",
    "\n",
    "# Create a combined data generator\n",
    "combined_train_generator = VideoDataGenerator(combined_train_videos, combined_train_labels, batch_size=4, shuffle=True, augment=True)\n"
   ],
   "id": "bddde4c8d28478eb",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:12:54.503450Z",
     "start_time": "2024-11-09T01:12:54.485269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create separate generators for violence and tiktok datasets\n",
    "violence_train_generator_no_aug = VideoDataGenerator(violence_train_videos, violence_train_labels_np, batch_size=4, shuffle=True, augment=False)\n",
    "tiktok_train_generator_no_aug = VideoDataGenerator(tiktok_train_videos, tiktok_train_labels_np, batch_size=4, shuffle=True, augment=False)\n",
    "\n",
    "# Create paired data generator\n",
    "paired_train_generator = PairedDataGenerator(violence_train_generator_no_aug, tiktok_train_generator_no_aug)\n",
    "\n",
    "\n"
   ],
   "id": "42ada6d418c9fe4e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:27:15.183781Z",
     "start_time": "2024-11-09T01:12:54.520011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "msupcl_model = load_c3d_model(input_shape=input_shape)\n",
    "\n",
    "# Train the model\n",
    "train_msupcl_model(msupcl_model, paired_train_generator, epochs=10)\n"
   ],
   "id": "73efa82bee2c74bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.7348\n",
      "Epoch 2/10\n",
      "Training Loss: 0.7323\n",
      "Epoch 3/10\n",
      "Training Loss: 0.7217\n",
      "Epoch 4/10\n",
      "Training Loss: 0.7297\n",
      "Epoch 5/10\n",
      "Training Loss: 0.7315\n",
      "Epoch 6/10\n",
      "Training Loss: 0.7242\n",
      "Epoch 7/10\n",
      "Training Loss: 0.7307\n",
      "Epoch 8/10\n",
      "Training Loss: 0.7272\n",
      "Epoch 9/10\n",
      "Training Loss: 0.7261\n",
      "Epoch 10/10\n",
      "Training Loss: 0.7242\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:33:35.792630Z",
     "start_time": "2024-11-09T01:27:15.210858Z"
    }
   },
   "cell_type": "code",
   "source": "linear_evaluation(msupcl_model, combined_train_generator,violence_val_generator, tiktok_val_generator)\n",
   "id": "e437717914dc10fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55/55 [==============================] - 72s 1s/step - loss: 11.0498 - sparse_categorical_accuracy: 0.4932 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.5357\n",
      "Epoch 2/5\n",
      "55/55 [==============================] - 72s 1s/step - loss: 6.7122 - sparse_categorical_accuracy: 0.4886 - val_loss: 1.8705 - val_sparse_categorical_accuracy: 0.5357\n",
      "Epoch 3/5\n",
      "55/55 [==============================] - 70s 1s/step - loss: 7.0818 - sparse_categorical_accuracy: 0.4841 - val_loss: 1.6976 - val_sparse_categorical_accuracy: 0.5357\n",
      "Epoch 4/5\n",
      "55/55 [==============================] - 73s 1s/step - loss: 6.0086 - sparse_categorical_accuracy: 0.5045 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 5/5\n",
      "55/55 [==============================] - 73s 1s/step - loss: 5.8902 - sparse_categorical_accuracy: 0.5159 - val_loss: 0.7459 - val_sparse_categorical_accuracy: 0.5000\n",
      "Evaluating on Violence Test Set:\n",
      "7/7 [==============================] - 5s 643ms/step - loss: 0.7155 - sparse_categorical_accuracy: 0.5000\n",
      "Violence Test Loss: 0.7154548764228821, Test Accuracy: 0.5\n",
      "Evaluating on TikTok Test Set:\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.7025 - sparse_categorical_accuracy: 0.6429\n",
      "TikTok Test Loss: 0.7024644017219543, Test Accuracy: 0.6428571343421936\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## R2+1d_18 model",
   "id": "9cb372ba1eb23a27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:24.373216Z",
     "start_time": "2024-11-09T01:37:22.948794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model_train_r2plus1d_18 import load_r2plus1d_model, linear_evaluation, train_msupcl_model, linear_evaluation\n",
    "\n",
    "input_shape = (16, 112, 112, 3)\n",
    "feature_dim = 512\n",
    "\n",
    "msupcl_model = load_r2plus1d_model(input_shape=input_shape, feature_dim=feature_dim, include_top=False)"
   ],
   "id": "79b199cbcef78608",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:37:24.388744Z",
     "start_time": "2024-11-09T01:37:24.377221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "\n",
    "violence_train_generator_no_aug = VideoDataGenerator(violence_train_videos, violence_train_labels_np, batch_size=batch_size, shuffle=True, augment=False)\n",
    "tiktok_train_generator_no_aug = VideoDataGenerator(tiktok_train_videos, tiktok_train_labels_np, batch_size=batch_size, shuffle=True, augment=False)\n",
    "paired_train_generator = PairedDataGenerator(violence_train_generator_no_aug, tiktok_train_generator_no_aug)"
   ],
   "id": "d6ca19638578676a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:50:49.846047Z",
     "start_time": "2024-11-09T01:37:24.405777Z"
    }
   },
   "cell_type": "code",
   "source": "train_msupcl_model(msupcl_model, paired_train_generator, epochs=10)",
   "id": "e99577651e50c31e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.7068\n",
      "Epoch 2/10\n",
      "Training Loss: 0.7050\n",
      "Epoch 3/10\n",
      "Training Loss: 0.7007\n",
      "Epoch 4/10\n",
      "Training Loss: 0.6996\n",
      "Epoch 5/10\n",
      "Training Loss: 0.6959\n",
      "Epoch 6/10\n",
      "Training Loss: 0.6910\n",
      "Epoch 7/10\n",
      "Training Loss: 0.7074\n",
      "Epoch 8/10\n",
      "Training Loss: 0.6976\n",
      "Epoch 9/10\n",
      "Training Loss: 0.7011\n",
      "Epoch 10/10\n",
      "Training Loss: 0.6987\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T01:57:44.916587Z",
     "start_time": "2024-11-09T01:51:37.568438Z"
    }
   },
   "cell_type": "code",
   "source": "linear_evaluation(msupcl_model, combined_train_generator, violence_val_generator,tiktok_val_generator, num_classes=2)",
   "id": "55d925dd4feb4f2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55/55 [==============================] - 71s 1s/step - loss: 1.0014 - sparse_categorical_accuracy: 0.4727 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.4643\n",
      "Epoch 2/5\n",
      "55/55 [==============================] - 69s 1s/step - loss: 0.6855 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.7238 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 3/5\n",
      "55/55 [==============================] - 69s 1s/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5386 - val_loss: 0.7181 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "55/55 [==============================] - 69s 1s/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5227 - val_loss: 0.7405 - val_sparse_categorical_accuracy: 0.3571\n",
      "Epoch 5/5\n",
      "55/55 [==============================] - 72s 1s/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5341 - val_loss: 0.7396 - val_sparse_categorical_accuracy: 0.5000\n",
      "Evaluating on Violence Test Set:\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 0.7471 - sparse_categorical_accuracy: 0.3571\n",
      "Violence Test Loss: 0.7471337914466858, Test Accuracy: 0.3571428656578064\n",
      "Evaluating on TikTok Test Set:\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6955 - sparse_categorical_accuracy: 0.5357\n",
      "TikTok Test Loss: 0.6955334544181824, Test Accuracy: 0.5357142686843872\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
