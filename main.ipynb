{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.436283Z",
     "start_time": "2024-11-08T23:43:40.945554Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, losses, optimizers, metrics\n",
    "\n",
    "from model_train import load_c3d_model, train_msupcl_model, linear_evaluation\n",
    "from data_uniform_sup import VideoDataGenerator\n",
    "from paired_generator import PairedDataGenerator"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.451984Z",
     "start_time": "2024-11-08T23:43:43.440256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 2042\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "input_shape = (16, 112, 112, 3)  # As defined in data generator\n",
    "num_classes = 2  # Harmful or Safe"
   ],
   "id": "dd29972a569d4e84",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.531152Z",
     "start_time": "2024-11-08T23:43:43.515597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define dataset paths\n",
    "violence_negative_dir = './data/violence_dataset/NonViolence'\n",
    "violence_positive_dir = './data/violence_dataset/Violence'\n",
    "tiktok_negative_dir = './data/tiktok/train/Safe'\n",
    "tiktok_positive_dir = './data/tiktok/train/Harmful Content'\n"
   ],
   "id": "38b4e7f27f35b855",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.563117Z",
     "start_time": "2024-11-08T23:43:43.548137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_videos(directory, num_samples=100):\n",
    "    all_videos = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.mp4')]\n",
    "    sampled_videos = random.sample(all_videos, min(num_samples, len(all_videos)))\n",
    "    return sampled_videos\n"
   ],
   "id": "69be9a7b8c19f6d5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.593117Z",
     "start_time": "2024-11-08T23:43:43.579131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Violence dataset\n",
    "violence_negative_videos = sample_videos(violence_negative_dir, 100)\n",
    "violence_positive_videos = sample_videos(violence_positive_dir, 100)\n",
    "\n",
    "# TikTok dataset\n",
    "tiktok_negative_videos = sample_videos(tiktok_negative_dir, 100)\n",
    "tiktok_positive_videos = sample_videos(tiktok_positive_dir, 100)\n"
   ],
   "id": "43cccf67e2dcc321",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.624705Z",
     "start_time": "2024-11-08T23:43:43.610163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_data(negative_videos, positive_videos, train_ratio=0.55, val_ratio=0.15):\n",
    "    # Combine and shuffle\n",
    "    videos = negative_videos + positive_videos\n",
    "    labels = [0]*len(negative_videos) + [1]*len(positive_videos)\n",
    "    combined = list(zip(videos, labels))\n",
    "    random.shuffle(combined)\n",
    "    videos[:], labels[:] = zip(*combined)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    total = len(videos)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = train_end + int(total * val_ratio)\n",
    "    \n",
    "    # Split data\n",
    "    train_videos = videos[:train_end]\n",
    "    train_labels = labels[:train_end]\n",
    "    val_videos = videos[train_end:val_end]\n",
    "    val_labels = labels[train_end:val_end]\n",
    "    test_videos = videos[val_end:]\n",
    "    test_labels = labels[val_end:]\n",
    "    \n",
    "    return (train_videos, train_labels), (val_videos, val_labels), (test_videos, test_labels)\n"
   ],
   "id": "f8fa8efe1d13ebf5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.656688Z",
     "start_time": "2024-11-08T23:43:43.641687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Violence dataset\n",
    "(violence_train_videos, violence_train_labels), \\\n",
    "(violence_val_videos, violence_val_labels), \\\n",
    "(violence_test_videos, violence_test_labels) = split_data(violence_negative_videos, violence_positive_videos)\n",
    "\n",
    "# TikTok dataset\n",
    "(tiktok_train_videos, tiktok_train_labels), \\\n",
    "(tiktok_val_videos, tiktok_val_labels), \\\n",
    "(tiktok_test_videos, tiktok_test_labels) = split_data(tiktok_negative_videos, tiktok_positive_videos)\n"
   ],
   "id": "17bc85a97ca94a61",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.688717Z",
     "start_time": "2024-11-08T23:43:43.673686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Convert labels to numpy arrays and one-hot encode them if necessary\n",
    "def prepare_labels(labels):\n",
    "    return np.array(labels)\n",
    "\n",
    "# Violence dataset generators\n",
    "violence_train_labels_np = prepare_labels(violence_train_labels)\n",
    "violence_val_labels_np = prepare_labels(violence_val_labels)\n",
    "violence_test_labels_np = prepare_labels(violence_test_labels)\n",
    "\n",
    "violence_train_generator = VideoDataGenerator(violence_train_videos, violence_train_labels_np, batch_size=4, shuffle=True, augment=True)\n",
    "violence_val_generator = VideoDataGenerator(violence_val_videos, violence_val_labels_np, batch_size=4, shuffle=False)\n",
    "violence_test_generator = VideoDataGenerator(violence_test_videos, violence_test_labels_np, batch_size=4, shuffle=False)"
   ],
   "id": "f150cbe36dce5ba1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:43.720252Z",
     "start_time": "2024-11-08T23:43:43.705731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# TikTok dataset generators\n",
    "tiktok_train_labels_np = prepare_labels(tiktok_train_labels)\n",
    "tiktok_val_labels_np = prepare_labels(tiktok_val_labels)\n",
    "tiktok_test_labels_np = prepare_labels(tiktok_test_labels)\n",
    "\n",
    "tiktok_train_generator = VideoDataGenerator(tiktok_train_videos, tiktok_train_labels_np, batch_size=4, shuffle=True, augment=True)\n",
    "tiktok_val_generator = VideoDataGenerator(tiktok_val_videos, tiktok_val_labels_np, batch_size=4, shuffle=False)\n",
    "tiktok_test_generator = VideoDataGenerator(tiktok_test_videos, tiktok_test_labels_np, batch_size=4, shuffle=False)\n"
   ],
   "id": "b129d04af287a968",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:44.657951Z",
     "start_time": "2024-11-08T23:43:43.737237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the model\n",
    "model = load_c3d_model(input_shape=input_shape, feature_dim=512)\n"
   ],
   "id": "b4c77a016021fe8f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:43:44.705324Z",
     "start_time": "2024-11-08T23:43:44.675926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modify the model to output class probabilities\n",
    "\n",
    "\n",
    "# Freeze the base model if desired\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add classification layer\n",
    "features = model.output\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(features)\n",
    "classification_model = models.Model(inputs=model.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "classification_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()]\n",
    ")\n"
   ],
   "id": "600a86c162f46bac",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:47:45.992618Z",
     "start_time": "2024-11-08T23:43:44.721891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train on Violence dataset\n",
    "history_violence = classification_model.fit(\n",
    "    violence_train_generator,\n",
    "    validation_data=violence_val_generator,\n",
    "    epochs=10\n",
    ")\n"
   ],
   "id": "80ad2bb7d4358a76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55/55 [==============================] - 27s 422ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.4727 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 23s 429ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.4864 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 24s 434ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.4455 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 24s 431ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.4909 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 24s 438ms/step - loss: 0.6938 - sparse_categorical_accuracy: 0.4591 - val_loss: 0.6929 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 24s 438ms/step - loss: 0.6937 - sparse_categorical_accuracy: 0.4455 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 24s 438ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.4682 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 24s 436ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.4455 - val_loss: 0.6931 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 24s 430ms/step - loss: 0.6931 - sparse_categorical_accuracy: 0.4864 - val_loss: 0.6932 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 24s 440ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5000 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.5333\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T23:47:56.064361Z",
     "start_time": "2024-11-08T23:47:46.009641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate on Violence test set\n",
    "results_violence = classification_model.evaluate(violence_test_generator)\n",
    "print(f\"Violence Dataset - Test Loss: {results_violence[0]}, Test Accuracy: {results_violence[1]}\")\n"
   ],
   "id": "63b234494c99c2b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 10s 331ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.4833\n",
      "Violence Dataset - Test Loss: 0.6931644678115845, Test Accuracy: 0.4833333194255829\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:00:53.762945Z",
     "start_time": "2024-11-08T23:47:56.080874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_tiktok = classification_model.fit(\n",
    "    tiktok_train_generator,\n",
    "    validation_data=tiktok_val_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate on TikTok test set\n",
    "results_tiktok = classification_model.evaluate(tiktok_test_generator)\n",
    "print(f\"TikTok Dataset - Test Loss: {results_tiktok[0]}, Test Accuracy: {results_tiktok[1]}\")"
   ],
   "id": "7b2014bcbf1669c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55/55 [==============================] - 76s 1s/step - loss: 0.6929 - sparse_categorical_accuracy: 0.5273 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 75s 1s/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5136 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 75s 1s/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5136 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6903 - sparse_categorical_accuracy: 0.5727 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.6947 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6899 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.6946 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6907 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.6957 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6894 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6897 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.6965 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 74s 1s/step - loss: 0.6883 - sparse_categorical_accuracy: 0.5545 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.4000\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.6944 - sparse_categorical_accuracy: 0.4500\n",
      "TikTok Dataset - Test Loss: 0.694369912147522, Test Accuracy: 0.44999998807907104\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MSupCL implementation",
   "id": "dcd22c96fe0ecab0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:00:53.794268Z",
     "start_time": "2024-11-09T00:00:53.780949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine training data from both datasets\n",
    "combined_train_videos = violence_train_videos + tiktok_train_videos\n",
    "combined_train_labels = violence_train_labels_np.tolist() + tiktok_train_labels_np.tolist()\n",
    "\n",
    "# Create a combined data generator\n",
    "combined_train_generator = VideoDataGenerator(combined_train_videos, combined_train_labels, batch_size=4, shuffle=True, augment=True)\n"
   ],
   "id": "bddde4c8d28478eb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:00:53.826316Z",
     "start_time": "2024-11-09T00:00:53.811252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create separate generators for violence and tiktok datasets\n",
    "violence_train_generator_no_aug = VideoDataGenerator(violence_train_videos, violence_train_labels_np, batch_size=4, shuffle=True, augment=False)\n",
    "tiktok_train_generator_no_aug = VideoDataGenerator(tiktok_train_videos, tiktok_train_labels_np, batch_size=4, shuffle=True, augment=False)\n",
    "\n",
    "# Create paired data generator\n",
    "paired_train_generator = PairedDataGenerator(violence_train_generator_no_aug, tiktok_train_generator_no_aug)\n",
    "\n",
    "\n"
   ],
   "id": "42ada6d418c9fe4e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:15:41.910236Z",
     "start_time": "2024-11-09T00:00:53.843816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "msupcl_model = load_c3d_model(input_shape=input_shape)\n",
    "\n",
    "# Train the model\n",
    "train_msupcl_model(msupcl_model, paired_train_generator, epochs=10)\n"
   ],
   "id": "73efa82bee2c74bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: nan\n",
      "Epoch 2/10\n",
      "Training Loss: nan\n",
      "Epoch 3/10\n",
      "Training Loss: nan\n",
      "Epoch 4/10\n",
      "Training Loss: nan\n",
      "Epoch 5/10\n",
      "Training Loss: nan\n",
      "Epoch 6/10\n",
      "Training Loss: nan\n",
      "Epoch 7/10\n",
      "Training Loss: nan\n",
      "Epoch 8/10\n",
      "Training Loss: nan\n",
      "Epoch 9/10\n",
      "Training Loss: nan\n",
      "Epoch 10/10\n",
      "Training Loss: nan\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:29:45.763917Z",
     "start_time": "2024-11-09T00:29:20.210535Z"
    }
   },
   "cell_type": "code",
   "source": "linear_evaluation(msupcl_model, combined_train_generator,violence_val_generator, tiktok_val_generator)\n",
   "id": "e437717914dc10fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 33/110 [========>.....................] - ETA: 52s - loss: nan - sparse_categorical_accuracy: 0.5152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mlinear_evaluation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsupcl_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcombined_train_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43mviolence_val_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtiktok_val_generator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\2024fall\\5341\\pj\\Autism-Diagnosis-Transfer-Learning\\model_train.py:197\u001B[0m, in \u001B[0;36mlinear_evaluation\u001B[1;34m(model, train_generator, val_generator1, val_generator2, num_classes)\u001B[0m\n\u001B[0;32m    190\u001B[0m classifier_model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[0;32m    191\u001B[0m     loss\u001B[38;5;241m=\u001B[39mlosses\u001B[38;5;241m.\u001B[39mSparseCategoricalCrossentropy(),\n\u001B[0;32m    192\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m),\n\u001B[0;32m    193\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[metrics\u001B[38;5;241m.\u001B[39mSparseCategoricalAccuracy()]\n\u001B[0;32m    194\u001B[0m )\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# Train the classifier on the combined dataset\u001B[39;00m\n\u001B[1;32m--> 197\u001B[0m \u001B[43mclassifier_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_generator1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# or any validation generator\u001B[39;49;00m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\n\u001B[0;32m    201\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;66;03m# Evaluate on test sets\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating on Violence Test Set:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
